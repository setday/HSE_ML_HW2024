{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание\n",
    "\n",
    "Установить Anaconda и Git. Создать репозиторий на GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy (+0.1)\n",
    "\n",
    "Написать функцию, которая на вход принимает список, а возвращает словарь со среднием, медианой и модой, например вот такой: `{\"mean\": ..., \"median\": ..., \"mode\": ...}`.\n",
    "\n",
    "Пример:\n",
    "\n",
    "```python\n",
    "\n",
    "func([0, 1, 1, 10, 5, 4, 3])\n",
    "\n",
    "# Должно вернуть: {\"mean\": 3.4285, \"median\": 3, \"mode\": 1}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution:\n",
    "\n",
    "def func( arr : list ) -> dict:\n",
    "    n = len( arr )\n",
    "    \n",
    "    sorted_arr = sorted( arr )\n",
    "    \n",
    "    mode_value = 0\n",
    "    mode_count = -1\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < n:\n",
    "        while j < n and sorted_arr[ i ] == sorted_arr[ j ]:\n",
    "            j += 1\n",
    "        if j - i > mode_count:\n",
    "            mode_count = j - i\n",
    "            mode_value = sorted_arr[ i ]\n",
    "        i = j\n",
    "\n",
    "    return {\n",
    "        \"mean\": sum( arr ) / n,\n",
    "        \"median\": sorted_arr[ n // 2 ],\n",
    "        \"mode\": max( arr, key=arr.count )\n",
    "        }\n",
    "\n",
    "def test_func():\n",
    "    assert func( [ 0, 1, 1, 10, 5, 4, 3 ]) == { \"mean\": 3.4285714285714284, \"median\": 3, \"mode\": 1 }\n",
    "    assert func( [ 0, 1, 2 ] ) == { \"mean\": 1, \"median\": 1, \"mode\": 0 }\n",
    "    assert func( [ 0, 1, 2, 2 ] ) == { \"mean\": 1.25, \"median\": 2, \"mode\": 2}\n",
    "\n",
    "test_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medium (+0.4)\n",
    "\n",
    "https://www.kaggle.com/datasets/databanditofficial/dota-hero-stats\n",
    "\n",
    "Написать функцию, которая будет парсить csv-файл dota_hero_stats.csv\n",
    "\n",
    "Сигнатура функции:\n",
    "\n",
    "```\n",
    "def parse_csv(file_content: str) -> List[Dict]\n",
    "```\n",
    "\n",
    "Найти персонажа с максимальным количеством ног (сторонние библиотеки использовать нельзя)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution:\n",
    "\n",
    "def separate_csv_line( line: str ) -> list[ str ]:\n",
    "    is_in_quotes = False\n",
    "    result = []\n",
    "    current = ''\n",
    "    for c in line:\n",
    "        if c == '\"':\n",
    "            is_in_quotes = not is_in_quotes\n",
    "        elif c == ',' and not is_in_quotes:\n",
    "            result.append( current )\n",
    "            current = ''\n",
    "        else:\n",
    "            current += c\n",
    "    result.append( current )\n",
    "    return result\n",
    "\n",
    "def parse_csv( file_content: str ) -> list[ dict ]:\n",
    "    lines = file_content.split( '\\n' )\n",
    "    keys = separate_csv_line( lines[ 0 ] )\n",
    "    table = []\n",
    "\n",
    "    for line in lines[ 1: ]:\n",
    "        line_data = separate_csv_line( line )\n",
    "\n",
    "        if len( line_data ) == len( keys ):\n",
    "            table.append( dict( zip( keys, line_data ) ) )\n",
    "    \n",
    "    return table\n",
    "\n",
    "def load_heroes_data():\n",
    "    with open( 'dota_hero_stats.csv' ) as f:\n",
    "        data = parse_csv( f.read() )\n",
    "    return data\n",
    "\n",
    "def find_by_max_legs( data: list[ dict ] ) -> dict:\n",
    "    return max( data, key = lambda x: int( x.get( 'legs', 0 ) ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hero with max legs: Broodmother (have 8 legs)\n"
     ]
    }
   ],
   "source": [
    "def test_parse_csv():\n",
    "    data = load_heroes_data()\n",
    "    hero = find_by_max_legs( data )\n",
    "    print( f'Hero with max legs: { hero.get( \"localized_name\" ) } (have { hero.get( \"legs\" ) } legs)' )\n",
    "\n",
    "test_parse_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard (+ в карму)\n",
    "\n",
    "Придумать меру близости между двумя персонажами, описать текстом, реализовать кодом. Мера должна использовать все содержательные колонки: attack_type, legs, primary_attr, roles\n",
    "\n",
    "Найти двух персонажей, которые наиболее близки друг к другу.\n",
    "\n",
    "Также нельзя использовать сторонние библиотеки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все характеристики разделим на три класса:\n",
    "- первостепенные (имеют наибольший вес): `primary_attr, roles` (в большнстве случаев роль + класс определяют основные характеристики атаки, здоровья и способностей персонажа, поэтому эти классификаторы наиболее ценны)\n",
    "- второстепенные (средний): `attack_type`\n",
    "- третистепенные (почти не имеют веса): `legs` (чисто визуальный элемент, который почти не должен влиять на близость)\n",
    "\n",
    "Веса отдаления распределим так:\n",
    "- первостепенные - $10$\n",
    "- второстепенные - $3$ (начинают влиять при сильных откланениях первостепенных)\n",
    "- третистепенные - $0.1$ (почти не влияют и нужны только в случае полного несовпадения первых двух)\n",
    "\n",
    "Сравнение по `roles` будем проверять как относительное онколение различных ролей от общего числа ролей $\\frac{count(legs_1 \\bigtriangleup legs_2)}{count(roles_1) + count(roles_2)}$\n",
    "\n",
    "Сравнение по `primary_attr` будет булевым: ```primary_attr_1 == primary_attr_2```\n",
    "\n",
    "Сравнение по `attack_type` будет булевым: ```attack_type_1 == attack_type_2```\n",
    "\n",
    "Сравнение по `legs` будем проверять как относительное онколение от наибольшего: $\\frac{|legs_1 - legs_2|}{\\max(legs_1, legs_2)}$\n",
    "\n",
    "Итоговой мерой отдалйнности будем считать длинну вектора отдалённостей классификаторов: $diff = \\sqrt{(\\Delta{roles} \\cdot primary\\_ weight)^2 + (\\Delta{primary\\_ attr} \\cdot primary\\_ weight)^2  + (\\Delta{attack\\_ type} \\cdot secondary\\_ weight)^2 + (\\Delta{legs} \\cdot thirdly\\_ weight)^2}$\n",
    "\n",
    "Мерой близости возмём $sim = (1 + diff)^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution:\n",
    "\n",
    "def compare_heroes( hero_1: dict, hero_2: dict ) -> float:\n",
    "    weights = {\n",
    "        'roles': 10,\n",
    "        'primary_attr': 10,\n",
    "        'attack_type': 3,\n",
    "        'legs': 0.1\n",
    "    }\n",
    "    diffs = {\n",
    "        'roles': 1,\n",
    "        'primary_attr': 1,\n",
    "        'attack_type': 1,\n",
    "        'legs': 1\n",
    "    }\n",
    "\n",
    "    if 'roles' in hero_1 and 'roles' in hero_2:\n",
    "        diffs[ 'roles' ] = len( set( hero_1[ 'roles' ] ) ^ set( hero_2[ 'roles' ] ) ) / ( len( hero_1[ 'roles' ] ) + len( hero_2[ 'roles' ] ) )\n",
    "\n",
    "    if 'primary_attr' in hero_1 and 'primary_attr' in hero_2:\n",
    "        diffs[ 'primary_attr' ] = int( hero_1[ 'primary_attr' ] != hero_2[ 'primary_attr' ] )\n",
    "\n",
    "    if 'attack_type' in hero_1 and 'attack_type' in hero_2:\n",
    "        diffs[ 'attack_type' ] = int( hero_1[ 'attack_type' ] != hero_2[ 'attack_type' ] )\n",
    "\n",
    "    if 'legs' in hero_1 and 'legs' in hero_2:\n",
    "        hero_1_legs = int( hero_1[ 'legs' ] )\n",
    "        hero_2_legs = int( hero_2[ 'legs' ] )\n",
    "\n",
    "        legs_diff = abs( hero_1_legs - hero_2_legs )\n",
    "\n",
    "        if legs_diff == 0:\n",
    "            diffs[ 'legs' ] = 0\n",
    "        else:\n",
    "            diffs[ 'legs' ] = abs( hero_1_legs - hero_2_legs ) / max( hero_1_legs , hero_2_legs )\n",
    "\n",
    "    result = 0\n",
    "    for key in weights:\n",
    "        result += (weights[ key ] * diffs[ key ]) ** 2\n",
    "\n",
    "    return (1 + result) ** -0.5\n",
    "\n",
    "def find_similar_heroes( heroes: list[ dict ] ) -> list[ dict ]:\n",
    "    result = []\n",
    "    similarity = 0\n",
    "    \n",
    "    for i in range( len( heroes ) ):\n",
    "        for j in range( i + 1, len( heroes ) ):\n",
    "            current_similarity = compare_heroes( heroes[ i ], heroes[ j ] )\n",
    "\n",
    "            if current_similarity > similarity:\n",
    "                similarity = current_similarity\n",
    "                result = [ heroes[ i ], heroes[ j ] ]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def find_unique_heroes( heroes: list[ dict ] ) -> list[ dict ]:\n",
    "    result = []\n",
    "    similarity = 1\n",
    "    \n",
    "    for i in range( len( heroes ) ):\n",
    "        for j in range( i + 1, len( heroes ) ):\n",
    "            current_similarity = compare_heroes( heroes[ i ], heroes[ j ] )\n",
    "\n",
    "            if current_similarity < similarity:\n",
    "                similarity = current_similarity\n",
    "                result = [ heroes[ i ], heroes[ j ] ]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar heroes: Crystal Maiden and Keeper of the Light (similarity: 1.0)\n",
      "Most unique heroes: Zeus and Phantom Assassin (similarity: 0.08826178722562064)\n"
     ]
    }
   ],
   "source": [
    "def test_find_similar_heroes():\n",
    "    data = load_heroes_data()\n",
    "    heroes = find_similar_heroes( data )\n",
    "    print( f'Most similar heroes: { heroes[ 0 ].get( \"localized_name\" ) } and { heroes[ 1 ].get( \"localized_name\" ) } (similarity: { compare_heroes( heroes[ 0 ], heroes[ 1 ] ) })' )\n",
    "\n",
    "test_find_similar_heroes()\n",
    "\n",
    "def test_find_unique_heroes():\n",
    "    data = load_heroes_data()\n",
    "    heroes = find_unique_heroes( data )\n",
    "    print( f'Most unique heroes: { heroes[ 0 ].get( \"localized_name\" ) } and { heroes[ 1 ].get( \"localized_name\" ) } (similarity: { compare_heroes( heroes[ 0 ], heroes[ 1 ] ) })' )\n",
    "\n",
    "test_find_unique_heroes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Байка\n",
    "\n",
    "В реально жизни, конечно, уже написаны парсеры для основных форматов данных, но кто вам гарантирует, что ваши данные будут в нужном формате? Нужно уметь парсить разные странные форматы данных.\n",
    "\n",
    "Когда-то я работал в компании, которая не умела в DWH и хранила все данные в продовых базах. Ну, \"базах\". Это были терабайты xml-файлов, поверх которых была настроена репликация и прод умел быстро по ним искать. Конечно же, эти xml-файлы были неструктурированы, пришлось освоить специальный язык для индексации по xml-файлам - xpath - чтобы привести данные в хоть сколько-то табличный вид. Парсер имел отвратительный код, а данные на выходе были еще хуже. А через пару месяцев я уволился оттуда и дальше проект не полетел (надеюсь, это независимые события). Какой вывод? Держите данные в DWH в понятном и удобном формате и не храните данные в проде в xml."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
